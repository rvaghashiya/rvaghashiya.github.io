<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research | Rajkumar Vaghashiya</title>
    <link>https://rvaghashiya.github.io/tag/research/</link>
      <atom:link href="https://rvaghashiya.github.io/tag/research/index.xml" rel="self" type="application/rss+xml" />
    <description>Research</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 Rajkumar Vaghashiya</copyright><lastBuildDate>Thu, 01 Jul 2021 23:07:00 +0000</lastBuildDate>
    <image>
      <url>https://rvaghashiya.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Research</title>
      <link>https://rvaghashiya.github.io/tag/research/</link>
    </image>
    
    <item>
      <title>MediSinGAN</title>
      <link>https://rvaghashiya.github.io/project/medisingan/</link>
      <pubDate>Thu, 01 Jul 2021 23:07:00 +0000</pubDate>
      <guid>https://rvaghashiya.github.io/project/medisingan/</guid>
      <description>&lt;h1 id=&#34;medisingan&#34;&gt;MediSinGAN&lt;/h1&gt;
&lt;p&gt;The aim is to use an unconditional generative model, SinGAN, to augment medical image datasets using a single natural image.&lt;/p&gt;
&lt;h2 id=&#34;current-progress&#34;&gt;Current Progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Implemented SinGAN architecture in JAX for the generation of realistic synthetic medical imaging data using a
single training image and achieved a 20% reduction in training time&lt;/li&gt;
&lt;li&gt;Evaluated the model applicability in MRI cross-modality image-to-image translation, Synthetic brain tumor
generation, and Medical image segmentation (Histopathology)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Smart, Portable, and Cost-effective ELISA Reader</title>
      <link>https://rvaghashiya.github.io/project/smart-portable-and-cost-effective-elisa-reader/</link>
      <pubDate>Tue, 01 Sep 2020 20:52:00 +0000</pubDate>
      <guid>https://rvaghashiya.github.io/project/smart-portable-and-cost-effective-elisa-reader/</guid>
      <description>&lt;h2 id=&#34;project-goals&#34;&gt;Project Goals&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cost-effective and portable ELISA reader with AI-aided analyzer and adaptive calibration&lt;/li&gt;
&lt;li&gt;Image processing based qualitative and quantitative real-time analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;current-progress&#34;&gt;Current Progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Completed precise micro-plate well localization&lt;/li&gt;
&lt;li&gt;Well localization utilizes bit plane slicing, masking and contouring, and shape appropriation&lt;/li&gt;
&lt;li&gt;Extracts basic color information, measuring light intensity in RBG colorspace, for each well&lt;/li&gt;
&lt;li&gt;Provides normalized measure of intenstity&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;note&#34;&gt;Note&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Uses standard well-reference: A-H for rows, 1 to 12 for columns&lt;/li&gt;
&lt;li&gt;‘00’ for base/reference well&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample: Segmented Microplate-wells (Pic shows a zoomed section of the microplate)














&lt;figure  id=&#34;figure-sample-segmented-microplate-wells-pic-shows-a-zoomed-section-of-the-microplate&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Sample: Segmented Microplate-wells (Pic shows a zoomed section of the microplate)&#34; srcset=&#34;
               /project/smart-portable-and-cost-effective-elisa-reader/contoured_img_hu20d3d7dcfa6274d9e4b60a1dae1d5de7_16657_ee13cb0d7f17f4595f0be4715be42a74.webp 400w,
               /project/smart-portable-and-cost-effective-elisa-reader/contoured_img_hu20d3d7dcfa6274d9e4b60a1dae1d5de7_16657_ed163542a81010576f295d9a5d408cde.webp 760w,
               /project/smart-portable-and-cost-effective-elisa-reader/contoured_img_hu20d3d7dcfa6274d9e4b60a1dae1d5de7_16657_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/smart-portable-and-cost-effective-elisa-reader/contoured_img_hu20d3d7dcfa6274d9e4b60a1dae1d5de7_16657_ee13cb0d7f17f4595f0be4715be42a74.webp&#34;
               width=&#34;169&#34;
               height=&#34;177&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Sample: Segmented Microplate-wells (Pic shows a zoomed section of the microplate)
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Locations of Segmented Wells














&lt;figure  id=&#34;figure-locations-of-segmented-wells&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Locations of Segmented Wells&#34; srcset=&#34;
               /project/smart-portable-and-cost-effective-elisa-reader/well_data_hu5562703155bdf9bf158192659d5bff43_4786_c46597e34fd211ba2beb7701ff22e21f.webp 400w,
               /project/smart-portable-and-cost-effective-elisa-reader/well_data_hu5562703155bdf9bf158192659d5bff43_4786_eb9bc0e029c48a47f8689a5cc521f7bb.webp 760w,
               /project/smart-portable-and-cost-effective-elisa-reader/well_data_hu5562703155bdf9bf158192659d5bff43_4786_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/smart-portable-and-cost-effective-elisa-reader/well_data_hu5562703155bdf9bf158192659d5bff43_4786_c46597e34fd211ba2beb7701ff22e21f.webp&#34;
               width=&#34;324&#34;
               height=&#34;220&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Locations of Segmented Wells
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;













&lt;figure  id=&#34;figure-a-cropped-well-filled-with-a-solution&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;A cropped Well filled with a solution&#34; srcset=&#34;
               /project/smart-portable-and-cost-effective-elisa-reader/45well_hu55e62f6a6d995c90bda7d56ffde7ca0a_1446_adce6e7a45d28fa5f5aa22ab0f92ebb0.webp 400w,
               /project/smart-portable-and-cost-effective-elisa-reader/45well_hu55e62f6a6d995c90bda7d56ffde7ca0a_1446_c5afa22f71805fd3cd8a4a8a6a5bf2ad.webp 760w,
               /project/smart-portable-and-cost-effective-elisa-reader/45well_hu55e62f6a6d995c90bda7d56ffde7ca0a_1446_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/smart-portable-and-cost-effective-elisa-reader/45well_hu55e62f6a6d995c90bda7d56ffde7ca0a_1446_adce6e7a45d28fa5f5aa22ab0f92ebb0.webp&#34;
               width=&#34;252&#34;
               height=&#34;252&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      A cropped Well filled with a solution
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;td&gt;













&lt;figure  id=&#34;figure-a-cropped-empty-well&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;A cropped empty Well&#34; srcset=&#34;
               /project/smart-portable-and-cost-effective-elisa-reader/56well_huf3e9149c03efb918d4cfa6ecf4da5565_2211_93b03f2a3558914e4f48122aff7aa7df.webp 400w,
               /project/smart-portable-and-cost-effective-elisa-reader/56well_huf3e9149c03efb918d4cfa6ecf4da5565_2211_92a11d340f05ccd1e4168cf6cbaacf8d.webp 760w,
               /project/smart-portable-and-cost-effective-elisa-reader/56well_huf3e9149c03efb918d4cfa6ecf4da5565_2211_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/smart-portable-and-cost-effective-elisa-reader/56well_huf3e9149c03efb918d4cfa6ecf4da5565_2211_93b03f2a3558914e4f48122aff7aa7df.webp&#34;
               width=&#34;252&#34;
               height=&#34;252&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      A cropped empty Well
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Well boundary colored has been colored for reference in the above figures.&lt;/p&gt;
&lt;h3 id=&#34;note-1&#34;&gt;Note:&lt;/h3&gt;
&lt;p&gt;Full work till date cannot be disclosed&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Smart, Portable, and Cost-effective ELISA Reader</title>
      <link>https://rvaghashiya.github.io/post/smart-portable-and-cost-effective-elisa-reader/index1/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://rvaghashiya.github.io/post/smart-portable-and-cost-effective-elisa-reader/index1/</guid>
      <description>&lt;h2 id=&#34;project-goals&#34;&gt;Project Goals&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cost-effective and portable ELISA reader with AI-aided diagnosis for adaptive calibration&lt;/li&gt;
&lt;li&gt;Image processing based qualitative and quantitative real-time analysis for improved sensitivity and specificity&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;current-progress&#34;&gt;Current Progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Completed precise micro-plate well localization&lt;/li&gt;
&lt;li&gt;Well localization utilizes bit plane slicing, masking and contouring, and shape appropriation&lt;/li&gt;
&lt;li&gt;Extracts basic color information, measuring light intensity in RBG colorspace, for each well&lt;/li&gt;
&lt;li&gt;Provides normalized measure of intenstity&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;note&#34;&gt;Note&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Uses standard well-reference: A-H for rows, 1 to 12 for columns&lt;/li&gt;
&lt;li&gt;‘00’ for base/reference well&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample: Segmented Microplate-wells (Pic shows a zoomed section of the microplate)














&lt;figure  id=&#34;figure-sample-segmented-microplate-wells-pic-shows-a-zoomed-section-of-the-microplate&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;contoured_img.png&#34; alt=&#34;Sample: Segmented Microplate-wells (Pic shows a zoomed section of the microplate)&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Sample: Segmented Microplate-wells (Pic shows a zoomed section of the microplate)
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Locations of Segmented Wells














&lt;figure  id=&#34;figure-locations-of-segmented-wells&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;well_data.png&#34; alt=&#34;Locations of Segmented Wells&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Locations of Segmented Wells
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;













&lt;figure  id=&#34;figure-a-cropped-well-filled-with-a-solution&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;45well.png&#34; alt=&#34;A cropped Well filled with a solution&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      A cropped Well filled with a solution
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;td&gt;













&lt;figure  id=&#34;figure-a-cropped-empty-well&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;56well.png&#34; alt=&#34;A cropped empty Well&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      A cropped empty Well
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Well boundary colored has been colored for reference in the above figures.&lt;/p&gt;
&lt;h3 id=&#34;note-1&#34;&gt;Note:&lt;/h3&gt;
&lt;p&gt;Full work till date cannot be disclosed&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intelligent Digital Inline Holographic Micrograph (DIHM) Cell-Enhancement and Characterization</title>
      <link>https://rvaghashiya.github.io/post/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/index1/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://rvaghashiya.github.io/post/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/index1/</guid>
      <description>&lt;h2 id=&#34;intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization&#34;&gt;Intelligent Digital Inline Holographic Micrograph (DIHM) Cell-Enhancement and Characterization&lt;/h2&gt;
&lt;h2 id=&#34;project-intro&#34;&gt;Project Intro&lt;/h2&gt;
&lt;p&gt;Developing a novel and efficient neural model for detecting and classifying cells such as RBC, WBC, and cancer cells, etc.(cellular pathology) from DIH(Digital Inline Holographic) microscopy images&lt;/p&gt;
&lt;p&gt;Implementation on a resource-constrained device to develop a cheap, reliable and portable point-of-care testing facility for diagnosis of pathological diseases, especially for usage in rural areas&lt;/p&gt;
&lt;h2 id=&#34;highlights&#34;&gt;Highlights&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Segment cell-lines in DIH micrograph; performs signal enhancement using CNN-based autoencoder, followed by the cell-line characterization&lt;/li&gt;
&lt;li&gt;ROC-AUC: &amp;gt;0.98 for RBC, WBC, and microbeads; &amp;gt;0.88 for cancer cells HepG2 and MCF7&lt;/li&gt;
&lt;li&gt;Easy accommodation of newer cell-lines. Python, TensorFlow, OpenCV&lt;/li&gt;
&lt;li&gt;Preliminary work &lt;a href=&#34;https://ieeexplore.ieee.org/document/9374330&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;published&lt;/a&gt; at the 8th IEEE ICHI&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  id=&#34;figure-breast-cancer-disease-statistics&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;img1.png&#34; alt=&#34;Breast Cancer Disease Statistics&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Breast Cancer Disease Statistics
    &lt;/figcaption&gt;&lt;/figure&gt;














&lt;figure  id=&#34;figure-limitations-of-traditional-optic-microscopy&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;img2.png&#34; alt=&#34;Limitations of Traditional Optic Microscopy&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Limitations of Traditional Optic Microscopy
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;aim&#34;&gt;Aim&lt;/h2&gt;
&lt;p&gt;The aim of the research is to create a&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cheap,&lt;/li&gt;
&lt;li&gt;Reliable,&lt;/li&gt;
&lt;li&gt;Adaptable,&lt;/li&gt;
&lt;li&gt;Portable, and&lt;/li&gt;
&lt;li&gt;Intelligent
real-time point-of-care testing facility that could be used in resource-constrained environments, especially such as those in a rural setting.&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;img3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;














&lt;figure  id=&#34;figure-cell-lines-used-in-the-project&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;cells.png&#34; alt=&#34;Cell-lines used in the project&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cell-lines used in the project
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;current-progress&#34;&gt;Current Progress&lt;/h2&gt;














&lt;figure  id=&#34;figure-cell-line-eda&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;img4.png&#34; alt=&#34;Cell-line EDA&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cell-line EDA
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The colored cell-lines is the result of EDA on the statistical properties and pixel intensity in the images&lt;/p&gt;
&lt;h2 id=&#34;segmentation-results&#34;&gt;Segmentation Results&lt;/h2&gt;














&lt;figure  id=&#34;figure-the-segmentation-involves-bit-plane-splicing-adaptive-thresholding-and-contour-approximation-to-crop-the-cell-lines&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;segmented_cells.png&#34; alt=&#34;The segmentation involves bit-plane splicing, adaptive thresholding, and contour approximation to crop the cell-lines&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The segmentation involves bit-plane splicing, adaptive thresholding, and contour approximation to crop the cell-lines
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;cnn-model-performance&#34;&gt;CNN Model Performance&lt;/h2&gt;














&lt;figure  id=&#34;figure-confusion-matrix&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;confmatrix_with_acc_prevv.png&#34; alt=&#34;Confusion Matrix&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Confusion Matrix
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The recognition performance of the CNN model on the augmented dataset&lt;/p&gt;
&lt;h2 id=&#34;final-cell-counts-for-the-input-micrograph&#34;&gt;Final Cell Counts for the Input Micrograph&lt;/h2&gt;














&lt;figure  id=&#34;figure-the-final-result-in-form-of-cell-counts-for-the-roi-region-of-interest-window-selected-in-the-dih-micrograph&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;final_count.png&#34; alt=&#34;The final result in form of cell-counts for the ROI (region of interest) window selected in the DIH micrograph&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The final result in form of cell-counts for the ROI (region of interest) window selected in the DIH micrograph
    &lt;/figcaption&gt;&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Secure &amp; Smart University</title>
      <link>https://rvaghashiya.github.io/post/secure-and-smart-university/index1/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://rvaghashiya.github.io/post/secure-and-smart-university/index1/</guid>
      <description>&lt;h2 id=&#34;project-goals&#34;&gt;Project Goals&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;IoT project to simulate a smart university for resource usage optimization, funded by ORSP-PDPU.&lt;/li&gt;
&lt;li&gt;Annual financial grant of ₹ 1,45,000 sanctioned by the university for the project development&lt;/li&gt;
&lt;li&gt;Prototype modules installed in Computer Lab: Light Control, Lab Temperature Control, Authorized Personnel Access.&lt;/li&gt;
&lt;li&gt;Raspberry Pi and Arduino (prototyping), MQTT (communication), Firebase/MongoDB (database), Python&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;Every industry in the world is incorporating smart devices to enhance their service and productivity— Healthcare via various wearable devices, Transport industry via the intelligent transport system, Agriculture industry via smart farming sensors and farm monitoring sensors.&lt;/p&gt;
&lt;p&gt;But very few researches are focused on the use of internet of things for improving quality of university working functionality as well as education. University campuses are ideal place to impart smart environment, and would pique student&amp;rsquo;s interest in learning about the latest equipment and tech.&lt;/p&gt;
&lt;p&gt;In this idea of a smart university, we will research on various modules for the smart university, available microcontrollers, communication protocols, and mobile applications as user interface. As an outcome of this project, we expect to design and implement robust architecture for the smart classroom.&lt;/p&gt;
&lt;p&gt;For the current project setup, we have focused on the aspects of smart classroom such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Smart Classroom&lt;/li&gt;
&lt;li&gt;Smart Energy Controller&lt;/li&gt;
&lt;li&gt;Smart Security&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following this, we will subsequently expand to other modules of a smart university.&lt;/p&gt;
&lt;h2 id=&#34;aim&#34;&gt;Aim&lt;/h2&gt;
&lt;p&gt;With an objective to implement secure smart university concept in PDPU campus, in a modular manner, following goals were achieved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PDPU becomes the first university of Gujarat to take step towards SMART University.&lt;/li&gt;
&lt;li&gt;Electricity consumption for the experimented room was found to reduce by a significant amount (20% percent electricity savings).&lt;/li&gt;
&lt;li&gt;The system permits constant monitoring of smoke and temperature which can help in an early identification of disaster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;modules-implemented-during-the-project&#34;&gt;Modules Implemented during the project&lt;/h2&gt;














&lt;figure  id=&#34;figure-virtual-setup-of-fully-automatic-smart-lights-for-labs&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;Module1.png&#34; alt=&#34;Virtual setup of fully automatic smart lights for labs&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Virtual setup of fully automatic smart lights for labs
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Different classes or labs have replication of same setup connected to a central MySQL Server. The setup includes IR Motion sensor and Thermal sensor to detect any motion in the lab and to check whether any person is there in the lab. Accordingly the lights connected to microcontroller via relay are turned on and off. All the data is recorded to SQL server which is used further for additional analytics.&lt;/p&gt;














&lt;figure  id=&#34;figure-virtual-setup-of-partially-automatic-smart-labs&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;Module2.png&#34; alt=&#34;Virtual setup of partially automatic smart labs&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Virtual setup of partially automatic smart labs
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;It shows smart AC, light and fan for any class or labs which are controlled and monitored by an android mobile application. Mobile application have authentication which ensures only trusted users/owners have control over it. All the commands sent by the mobile apps and the responses to it are stored in the SQL database.&lt;/p&gt;
&lt;h2 id=&#34;report&#34;&gt;Report&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/file/d/1eYKJPjkcWY9G9gl6tPw9Nrq2l8Xxx5Mw/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Energy Aware IoT based Automated Smart Lighting and CCTV System using MQTT and MySQL&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.warse.org/IJATCSE/static/pdf/file/ijatcse24816sl2019.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IoT – Principles and Paradigms&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Secure and Smart University</title>
      <link>https://rvaghashiya.github.io/project/secure-and-smart-university/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://rvaghashiya.github.io/project/secure-and-smart-university/</guid>
      <description>&lt;h2 id=&#34;project-goals&#34;&gt;Project Goals&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;IoT project to simulate a smart university for resource usage optimization, funded by ORSP-PDPU.&lt;/li&gt;
&lt;li&gt;Annual financial grant of ₹ 1,45,000 sanctioned by the university for the project development&lt;/li&gt;
&lt;li&gt;Prototype modules installed in Computer Lab: Light Control, Lab Temperature Control, Authorized Personnel Access.&lt;/li&gt;
&lt;li&gt;Raspberry Pi and Arduino, MQTT , Firebase/MongoDB , Python&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;Every industry in the world is incorporating smart devices to enhance their service and productivity— Healthcare via various wearable devices, Transport industry via the intelligent transport system, Agriculture industry via smart farming sensors and farm monitoring sensors.&lt;/p&gt;
&lt;p&gt;But very few researches are focused on the use of internet of things for improving quality of university working functionality as well as education. University campuses are ideal place to impart smart environment, and would pique student&amp;rsquo;s interest in learning about the latest equipment and tech.&lt;/p&gt;
&lt;p&gt;In this idea of a smart university, we will research on various modules for the smart university, available microcontrollers, communication protocols, and mobile applications as user interface. As an outcome of this project, we expect to design and implement robust architecture for the smart classroom.&lt;/p&gt;
&lt;p&gt;For the current project setup, we have focused on the aspects of smart classroom such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Smart Classroom&lt;/li&gt;
&lt;li&gt;Smart Energy Controller&lt;/li&gt;
&lt;li&gt;Smart Security&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following this, we will subsequently expand to other modules of a smart university.&lt;/p&gt;
&lt;h2 id=&#34;aim&#34;&gt;Aim&lt;/h2&gt;
&lt;p&gt;With an objective to implement secure smart university concept in PDPU campus, in a modular manner, following goals were achieved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PDPU becomes the first university of Gujarat to take step towards SMART University.&lt;/li&gt;
&lt;li&gt;Electricity consumption for the experimented room was found to reduce by a significant amount (20% percent electricity savings).&lt;/li&gt;
&lt;li&gt;The system permits constant monitoring of smoke and temperature which can help in an early identification of disaster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;modules-implemented-during-the-project&#34;&gt;Modules Implemented during the project&lt;/h2&gt;














&lt;figure  id=&#34;figure-virtual-setup-of-fully-automatic-smart-lights-for-labs&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Virtual setup of fully automatic smart lights for labs&#34; srcset=&#34;
               /project/secure-and-smart-university/Module1_hu272ca4e16d9952599a12d9135b76d3e4_266518_4377c651b5e5c2c3164774e1e5edde88.webp 400w,
               /project/secure-and-smart-university/Module1_hu272ca4e16d9952599a12d9135b76d3e4_266518_2ed14550ec7290ea6fc8cdb12daad3bb.webp 760w,
               /project/secure-and-smart-university/Module1_hu272ca4e16d9952599a12d9135b76d3e4_266518_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/secure-and-smart-university/Module1_hu272ca4e16d9952599a12d9135b76d3e4_266518_4377c651b5e5c2c3164774e1e5edde88.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Virtual setup of fully automatic smart lights for labs
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Different classes or labs have replication of same setup connected to a central MySQL Server. The setup includes IR Motion sensor and Thermal sensor to detect any motion in the lab and to check whether any person is there in the lab. Accordingly the lights connected to microcontroller via relay are turned on and off. All the data is recorded to SQL server which is used further for additional analytics.&lt;/p&gt;














&lt;figure  id=&#34;figure-virtual-setup-of-partially-automatic-smart-labs&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Virtual setup of partially automatic smart labs&#34; srcset=&#34;
               /project/secure-and-smart-university/Module2_hucf53cf6cb021d45fb01cd5fe71a45b9e_245120_d7ae478e0ed90bb8d31cf93d117dceab.webp 400w,
               /project/secure-and-smart-university/Module2_hucf53cf6cb021d45fb01cd5fe71a45b9e_245120_d681454228d57c8cea29e9178743e2cf.webp 760w,
               /project/secure-and-smart-university/Module2_hucf53cf6cb021d45fb01cd5fe71a45b9e_245120_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/secure-and-smart-university/Module2_hucf53cf6cb021d45fb01cd5fe71a45b9e_245120_d7ae478e0ed90bb8d31cf93d117dceab.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Virtual setup of partially automatic smart labs
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;It shows smart AC, light and fan for any class or labs which are controlled and monitored by an android mobile application. Mobile application have authentication which ensures only trusted users/owners have control over it. All the commands sent by the mobile apps and the responses to it are stored in the SQL database.&lt;/p&gt;
&lt;h2 id=&#34;report&#34;&gt;Report&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/file/d/1eYKJPjkcWY9G9gl6tPw9Nrq2l8Xxx5Mw/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Energy Aware IoT based Automated Smart Lighting and CCTV System using MQTT and MySQL&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.warse.org/IJATCSE/static/pdf/file/ijatcse24816sl2019.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IoT – Principles and Paradigms&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intelligent Digital Inline Holographic Micrograph (DIHM) Cell-Enhancement and Characterization</title>
      <link>https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/</link>
      <pubDate>Mon, 07 Jan 2019 21:20:00 +0000</pubDate>
      <guid>https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/</guid>
      <description>&lt;h2 id=&#34;project-intro&#34;&gt;Project Intro&lt;/h2&gt;
&lt;p&gt;Developing a novel and efficient neural model for detecting and classifying cells such as RBC, WBC, and cancer cells, etc. (cellular pathology) from DIH (Digital Inline Holographic) microscopy images&lt;/p&gt;
&lt;p&gt;Implementation on a resource-constrained device to develop a cheap, reliable and portable point-of-care testing facility for diagnosis of pathological diseases, especially for usage in rural areas&lt;/p&gt;
&lt;h2 id=&#34;highlights&#34;&gt;Highlights&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Segment cell-lines in DIH micrograph; performs signal enhancement using CNN-based autoencoder, followed by the cell-line characterization&lt;/li&gt;
&lt;li&gt;ROC-AUC: &amp;gt;0.98 for RBC, WBC, and microbeads; &amp;gt;0.88 for cancer cells HepG2 and MCF7&lt;/li&gt;
&lt;li&gt;Easy accommodation of newer cell-lines. Python, TensorFlow, OpenCV&lt;/li&gt;
&lt;li&gt;Preliminary work &lt;a href=&#34;https://ieeexplore.ieee.org/document/9374330&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;published&lt;/a&gt; at the 8th IEEE International Conference on Healthcare Informatics (ICHI) 2020&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  id=&#34;figure-breast-cancer-disease-statistics&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Breast Cancer Disease Statistics&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img1_hu8ac06d34c690e9869143e5654758e9be_185519_372a6e66c3d543e58c2e4463a6763991.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img1_hu8ac06d34c690e9869143e5654758e9be_185519_c8a89f720056f3376ff6ecb85052b26c.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img1_hu8ac06d34c690e9869143e5654758e9be_185519_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img1_hu8ac06d34c690e9869143e5654758e9be_185519_372a6e66c3d543e58c2e4463a6763991.webp&#34;
               width=&#34;666&#34;
               height=&#34;292&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Breast Cancer Disease Statistics
    &lt;/figcaption&gt;&lt;/figure&gt;














&lt;figure  id=&#34;figure-limitations-of-traditional-optic-microscopy&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Limitations of Traditional Optic Microscopy&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img2_hub55ec7b5fd66b1f4d1af27ec086b55cb_100527_2e91625c9bfa906ab24a782a153663c5.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img2_hub55ec7b5fd66b1f4d1af27ec086b55cb_100527_bfeb7724d28b007ca743515bd781ff8b.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img2_hub55ec7b5fd66b1f4d1af27ec086b55cb_100527_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img2_hub55ec7b5fd66b1f4d1af27ec086b55cb_100527_2e91625c9bfa906ab24a782a153663c5.webp&#34;
               width=&#34;702&#34;
               height=&#34;406&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Limitations of Traditional Optic Microscopy
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;aim&#34;&gt;Aim&lt;/h2&gt;
&lt;p&gt;The aim of the research is to create a&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cheap,&lt;/li&gt;
&lt;li&gt;Reliable,&lt;/li&gt;
&lt;li&gt;Adaptable,&lt;/li&gt;
&lt;li&gt;Portable, and&lt;/li&gt;
&lt;li&gt;Intelligent
real-time point-of-care testing facility that could be used in resource-constrained environments, especially such as those in a rural setting.&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img3_hu3437bf12853f01934bb7d5a92b93994c_57883_90082e489b54f54d869006d213771d77.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img3_hu3437bf12853f01934bb7d5a92b93994c_57883_5468ee5527d4cdabb8746277caacd5ed.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img3_hu3437bf12853f01934bb7d5a92b93994c_57883_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img3_hu3437bf12853f01934bb7d5a92b93994c_57883_90082e489b54f54d869006d213771d77.webp&#34;
               width=&#34;728&#34;
               height=&#34;412&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;














&lt;figure  id=&#34;figure-cell-lines-used-in-the-project&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cell-lines used in the project&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/cells_hudd1927cb78bec53e9676f04b0e2d8b7b_109686_43d132f6a19ad3c3da228296f90083b6.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/cells_hudd1927cb78bec53e9676f04b0e2d8b7b_109686_00bd1132fd841a9c6e0ade09ba5542e1.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/cells_hudd1927cb78bec53e9676f04b0e2d8b7b_109686_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/cells_hudd1927cb78bec53e9676f04b0e2d8b7b_109686_43d132f6a19ad3c3da228296f90083b6.webp&#34;
               width=&#34;602&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cell-lines used in the project
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;current-progress&#34;&gt;Current Progress&lt;/h2&gt;














&lt;figure  id=&#34;figure-cell-line-eda&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cell-line EDA&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img4_hua953d76968a823f2abe1a0204f1da5bb_158154_8637535f1ba9b5a304186cf28b9110c6.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img4_hua953d76968a823f2abe1a0204f1da5bb_158154_6aaf997381c2b7f1caf105394378648a.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img4_hua953d76968a823f2abe1a0204f1da5bb_158154_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/img4_hua953d76968a823f2abe1a0204f1da5bb_158154_8637535f1ba9b5a304186cf28b9110c6.webp&#34;
               width=&#34;712&#34;
               height=&#34;370&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cell-line EDA
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The colored cell-lines is the result of EDA on the statistical properties and pixel intensity in the images&lt;/p&gt;
&lt;h2 id=&#34;segmentation-results&#34;&gt;Segmentation Results&lt;/h2&gt;














&lt;figure  id=&#34;figure-the-segmentation-involves-bit-plane-splicing-adaptive-thresholding-and-contour-approximation-to-crop-the-cell-lines&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The segmentation involves bit-plane splicing, adaptive thresholding, and contour approximation to crop the cell-lines&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/segmented_cells_hub292d90b0ae535b51923518faf2fcee3_120666_b2157c04a6f7c59bc70ddc1d36639a9c.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/segmented_cells_hub292d90b0ae535b51923518faf2fcee3_120666_c3696f85409aa5b7128ba415714ef70e.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/segmented_cells_hub292d90b0ae535b51923518faf2fcee3_120666_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/segmented_cells_hub292d90b0ae535b51923518faf2fcee3_120666_b2157c04a6f7c59bc70ddc1d36639a9c.webp&#34;
               width=&#34;738&#34;
               height=&#34;334&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The segmentation involves bit-plane splicing, adaptive thresholding, and contour approximation to crop the cell-lines
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;cnn-model-performance&#34;&gt;CNN Model Performance&lt;/h2&gt;














&lt;figure  id=&#34;figure-confusion-matrix&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Confusion Matrix&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/confmatrix_with_acc_prevv_hu57938ce728a6ebcdb8a739e041244294_158370_3db7f5983ffe1f653359c13fe18caad2.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/confmatrix_with_acc_prevv_hu57938ce728a6ebcdb8a739e041244294_158370_98d6d264a32292389bdfa0af6af3ab36.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/confmatrix_with_acc_prevv_hu57938ce728a6ebcdb8a739e041244294_158370_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/confmatrix_with_acc_prevv_hu57938ce728a6ebcdb8a739e041244294_158370_3db7f5983ffe1f653359c13fe18caad2.webp&#34;
               width=&#34;760&#34;
               height=&#34;634&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Confusion Matrix
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The recognition performance of the CNN model on the augmented dataset&lt;/p&gt;
&lt;h2 id=&#34;final-cell-counts-for-the-input-micrograph&#34;&gt;Final Cell Counts for the Input Micrograph&lt;/h2&gt;














&lt;figure  id=&#34;figure-the-final-result-in-form-of-cell-counts-for-the-roi-region-of-interest-window-selected-in-the-dih-micrograph&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The final result in form of cell-counts for the ROI (region of interest) window selected in the DIH micrograph&#34; srcset=&#34;
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/final_count_hu4532d829720968e51c8a947e44bbd19c_17679_36a01fe2847a7411d717fc2320bd3d1e.webp 400w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/final_count_hu4532d829720968e51c8a947e44bbd19c_17679_c18645217578b81a0af074f6aeceb997.webp 760w,
               /project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/final_count_hu4532d829720968e51c8a947e44bbd19c_17679_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://rvaghashiya.github.io/project/intelligent-digital-inline-holographic-micrograph-dihm-cell-enhancement-and-characterization/final_count_hu4532d829720968e51c8a947e44bbd19c_17679_36a01fe2847a7411d717fc2320bd3d1e.webp&#34;
               width=&#34;630&#34;
               height=&#34;470&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The final result in form of cell-counts for the ROI (region of interest) window selected in the DIH micrograph
    &lt;/figcaption&gt;&lt;/figure&gt;
</description>
    </item>
    
  </channel>
</rss>
